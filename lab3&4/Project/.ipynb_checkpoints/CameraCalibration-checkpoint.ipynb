{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78389fa-0d2c-4c61-b5fa-036f71ce5cc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Camera Calibration\n",
    "\n",
    "Before we can gather any information from whatever picture, we ought to obtain the parameters of our sensor(s). Which in this case is the camera. \n",
    "<br/> Therefore, we'll start with the camera calibration using the _chessboard_ provided at the beggining of the assignment.\n",
    "<br/>\n",
    "In short, camera calibration is estimating the parameters of a camera. <br/>\n",
    "- On the one side, we'll need intrinsic parameters like the focal length (f_x, f_y) and optical centers (c_x, c_y), which will be used to create the camera matrix. Which in turn will be used to remove distortion due to the lenses of a specific camera. Each camera having it's own distortion, meaning that once the camera calibration has been calculated we will be able to use said matrix for future operations using the same camera. </br>\n",
    "- On the other side, we'll need extrinsic parameters, meaning rotation and translation vectors which translate coordinate points of a 3D point to a coordinate system.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### Step 1\n",
    "For starters we'll need to define the size and dimension of our _chessboard_. \n",
    "<br/>\n",
    "It's dimension is defined by the amount of pixels along the width and the lenght of an image, in this case we're working with 1920x1080.\n",
    "And it's size is defined as the number of intersections between the black and grey squares that make up the _chessboard_, which in this case represents a 7x7, which corresponds to the pattern we are looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278d10da-9ac2-41d8-b92a-d55842438457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import PIL.ExifTags\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "#chessboard dimensions\n",
    "chessboardSize = (7, 7)\n",
    "frameSize = (1920, 1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf21d9-c2eb-4c65-9a23-9903688103d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2\n",
    "Next, we'll need to define the termination criteria, i.e, the \"Limit on number of iterations: When the limit on number of iterations or number of function evaluations exceeds a specified value, the iteration is terminated\" [^1]. <br/>\n",
    "For this purpose we'll use the two classes TERM_CRITERIA_EPS and TERM_CRITERIA_MAX_ITER: <br/>\n",
    "- TERM_CRITERIA_EPS = stop the algorithm iteration if specified accuracy, epsilon, is reached\n",
    "- TERM_CRITERIA_MAX_ITER = stop the algorithm after the specified number of iterations, max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bb4aa6-e0ba-4b68-a624-0bf65eb7e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271de1d-edbb-4294-b6aa-4edc4caf6eea",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "For simplicity's sake, we suppose that the _chessboard_ is stationary and thus we do not need to consider the _Z_ variables (_Z = 0_).</br>\n",
    "With this information in mind, we can already prepare  _XY_ coordinates of object points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e26f51-30fa-4037-9c1d-50be34784800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((7*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:7].T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9feeaf-559a-4b7a-b7f4-4c6dd10e28b7",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Prepare arrays to store our object points (3D) and image points (2D) and fetch _chessboard_ images with the glob function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ca60a1-d2a4-41a5-8b6e-9bec6a2a922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "#pc\n",
    "images = sorted(glob.glob(r'C:\\Users\\edgar\\Desktop\\Github\\ImageProcessing\\lab3&4\\chessboards\\*.png'))\n",
    "#laptop\n",
    "#images = sorted(glob.glob(r'C:\\Users\\edgar\\Documents\\GitHub\\ImageProcessing\\lab3&4\\chessboards\\*.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc376d-6447-4280-a7bd-3342d516f0a1",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "Use cv.findChessboardCorners() to find the aforementioned pattern in the _chessboard_. And once the corners have been found, use cv.cornerSubPix() to increase their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b873c4-07e5-4a13-8305-d042378c0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, chessboardSize, None)\n",
    "    \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, chessboardSize, corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40f76e0-29d4-43fb-9629-e7a02b0a5b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1920x1080 at 0x21AC65EF4C0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m exif_img \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(exif_img)\n\u001b[0;32m      4\u001b[0m exif_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m  PIL\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mTAGS[k]:v\n\u001b[1;32m----> 6\u001b[0m  \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexif_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getexif\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[0;32m      7\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m PIL\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mTAGS}\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Get focal length in tuple form\u001b[39;00m\n\u001b[0;32m     10\u001b[0m focal_length_exif \u001b[38;5;241m=\u001b[39m exif_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFocalLength\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#Get exif data in order to get focal length. \n",
    "exif_img = PIL.Image.open(images[0])\n",
    "\n",
    "exif_data = {\n",
    " PIL.ExifTags.TAGS[k]:v\n",
    " for k, v in exif_img._getexif().items()\n",
    " if k in PIL.ExifTags.TAGS}\n",
    "\n",
    "#Get focal length in tuple form\n",
    "focal_length_exif = exif_data['FocalLength']\n",
    "\n",
    "#Get focal length in decimal form\n",
    "focal_length = focal_length_exif[0]/focal_length_exif[1]\n",
    "np.save(\"./camera_params/FocalLength\", focal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21073fbb-a5a9-4f93-a858-df4834916f7a",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "Using the cv.calibrateCamera(), we can start the actual camera calibration. This will create the camera matrix, distortion coefficients, rotation and translation vectors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab1a7d14-3e88-4792-bb50-da63679625f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "#Save parameters into numpy file\n",
    "np.save(\"./lab3&4/cameraParams/ret\", ret)\n",
    "np.save(\"./lab3&4/cameraParams/mtx\", mtx)\n",
    "np.save(\"./lab3&4/cameraParams/dist\", dist)\n",
    "np.save(\"./lab3&4/cameraParams/rvecs\", rvecs)\n",
    "np.save(\"./lab3&4/cameraParams/tvecs\", tvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b5842-d00f-4520-9c7f-935d33a1fb74",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "Using the cv.getOptimalNewCameraMatrix() we can refine the camera matrix based on a free scaling parameter. Alpha being the scaling parameter, we can choose it's value based on our application. For instance, if we need to see all the input pixels, then alpha = 1. Otherwise, we choose an alpha that keeps the intersting part of the image inside the undistorted image. This process allows us to undistort the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97dcc6a-3fb0-46e9-b0a5-76d5fbc84dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc\n",
    "#img = cv.imread(r'C:\\Users\\edgar\\Desktop\\Github\\ImageProcessing\\lab3&4\\chessboards\\c4Left.png')\n",
    "#laptop\n",
    "img = cv.imread(r'C:\\Users\\edgar\\Documents\\GitHub\\ImageProcessing\\lab3&4\\chessboards\\c4Left.png')\n",
    "\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf006fb-9065-4842-b66f-fa57d4a90840",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "To achieve the undistortion, we may use two methods for this:\n",
    " - Using cv.undistort()\n",
    " - Using remapping\n",
    "\n",
    "For the purposes of this project, we'll use the undistort() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e62647-561c-49cc-a0ff-33ceca55dadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9f482-2a77-4aee-abba-46d6bff16909",
   "metadata": {
    "tags": []
   },
   "source": [
    "[^1]: https://www.sciencedirect.com/topics/engineering/termination-criterion#:~:text=Termination%20Criteria&text=1.,sense%2C%20the%20iteration%20is%20terminated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
